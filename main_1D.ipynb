{"cells":[{"cell_type":"markdown","metadata":{"id":"7d23b4ce"},"source":["# Aproximación de una Gaussiana con 1 qubit\n","\n","[1] Adrián Pérez Salinas et al, Quantum 4, 226 (2020) https://quantum-journal.org/papers/q-2020-02-06-226/\n","\n","Vamos a crear un modelo para aproximar una función $f(x)$ gaussiana con valores entre 0 y 1 (aproximadamente) con un solo qubit. Lo haremos siguiendo la idea del data reuploading, efectuando sucesivas rotaciones dependientes de x a un vector inicial $|0\\rangle$. Para ello, lo primero que tenemos que tener es un muestreo de la Gaussiana, que lo haremos con numpy."]},{"cell_type":"markdown","metadata":{"id":"69f09062"},"source":["### Import necessary packages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"882d2d7c"},"outputs":[],"source":["%load_ext line_profiler"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"e9c1a0d8"},"outputs":[],"source":["# file: main_1D.py\n","# coding=UTF-8\n","from typing import Optional\n","import numpy as np\n","from numpy import pi\n","import matplotlib.style as style\n","import matplotlib.pyplot as plt\n","from scipy.optimize import minimize, check_grad\n","import scipy.integrate as integrate\n","import pickle\n","#from qiskit.algorithms.optimizers import SPSA\n","# from pathos.multiprocessing import ProcessingPool, cpu_count\n","# from mpi4py import MPI\n","# import dill\n","#from multiprocessing import Pool, cpu_count"]},{"cell_type":"markdown","metadata":{"id":"c616b07a"},"source":["## Creating the layers"]},{"cell_type":"markdown","metadata":{"id":"71210c3b"},"source":["Una vez que tenemos nuestra función, podemos comenzar a aproximarla. Dado vector en la base $\\{(1,0),(0,1)\\}$, que simbolizará un qubit en la base $|0\\rangle,|1\\rangle$, queremos obtener un vector dependiente de $x$ tal que la primera componenete codifique el valor de f(x). Dado un conjunto de ángulos $\\phi_x$, $\\phi_y$ y $\\phi_z$, podemos parametrizar rotaciones en los ejes $x$, $y$, $z$ del cúbit en la esfera de Bloch. Estas rotaciones son matrices unitarias dadas por\n","\n","$$R=\\text{exp}\\,\\{i \\,(\\phi_x \\sigma_x+\\phi_y \\sigma_y+\\phi_z \\sigma_z)\\}=\\text{exp}\\,\\{i \\,\\phi\\,(n_x \\sigma_x+n_y \\sigma_y+n_z \\sigma_z)\\}\\:,$$"]},{"cell_type":"markdown","metadata":{"id":"6d1ff793"},"source":["Teniendo en cuenta que $\\{\\sigma_i,\\sigma_j\\}=2\\delta_{ij}\\mathbb{I}\\:$ y $\\:\\sigma_i^2=\\mathbb{I}$ deducimos que\n","$$(n_x \\sigma_x+n_y \\sigma_y+n_z \\sigma_z)^2=\\mathbb{I}\\:.$$\n","Podemos reescribir la rotación como \n","$$R=\\mathbb{I}\\,\\cos{\\phi}+i \\,n\\cdot\\sigma \\,\\sin{\\phi}$$"]},{"cell_type":"markdown","metadata":{"id":"626df09a"},"source":["La identidad y las matrices de Pauli son\n","\n","$$I = \\begin{pmatrix}1 & 0 \\\\ 0 & 1 \\end{pmatrix}\\:,\\qquad\\sigma_x = \\begin{pmatrix}0 & 1 \\\\ 1 & 0 \\end{pmatrix}\\:,\\qquad \\sigma_y = \\begin{pmatrix}0 & -i \\\\ i & 0 \\end{pmatrix}\\:,\\qquad \\sigma_y = \\begin{pmatrix}1 & 0 \\\\ 0 & -1 \\end{pmatrix}$$\n"]},{"cell_type":"markdown","metadata":{"id":"3e9d5b78"},"source":["En nuestro caso, las rotaciones en el eje $x$ dependerán de un punto x de la malla en la que aproximamos la función, de forma que en cada capa de la red neuronal se vuelva a incluir esta información. Así, escogemos los ángulos \n","\n","$$\\phi_1 = w\\,\\text{x} + \\theta_0$$\n","$$\\phi_2 = \\theta_1 \\qquad\\:\\,$$ \n","$$\\phi_3 = \\theta_2 \\qquad\\:\\,$$\n","\n","ya que consideramos solo funciones de una variable."]},{"cell_type":"markdown","metadata":{"id":"347cfa05"},"source":["## Creating our machine learning model"]},{"cell_type":"markdown","metadata":{"id":"396f69b4"},"source":["Each layer is an arbitrary unitary matrix\n","$$U_i(\\phi_1, \\phi_2, \\phi_3) = \\begin{pmatrix} \\cos{(\\phi_1/2)}\\, e^{i(\\phi_2+\\phi_3)/2} & -\\sin{(\\phi_1/2)}\\, e^{-i(\\phi_2-\\phi_3)/2} \\\\ \\sin{(\\phi_1/2)}\\, e^{i(\\phi_2-\\phi_3)/2} & \\cos{(\\phi_1/2)}\\, e^{-i(\\phi_2+\\phi_3)/2}  \\end{pmatrix}$$"]},{"cell_type":"markdown","metadata":{"id":"e5f9b799"},"source":["The following function returns the three rotations:"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"e297dd3a"},"outputs":[],"source":["# file: main_1D.py\n","def layer(x: np.ndarray, θi: np.ndarray, wi: float) -> tuple:\n","    \"\"\"\n","    Single qubit rotations.\n","    \n","    Parmeters\n","    ---------\n","    x : (G) array\n","        Grid of independent variables used to approximate the function.\n","    θ : (L,3) array\n","        Bias parameters of every layer.\n","    w : (L) array\n","        Weights of every layer.\n","    \n","    Returns\n","    -------\n","    A : (L,G,2,2) array\n","    Unitary matrices of each layer.\n","    \n","    References\n","    ----------\n","    [1] Adrián Pérez Salinas et al, \"Data re-uploading for a universal\n","        quantum classifier Quantum\" 4, 226 (2020)\n","        \n","    \"\"\"\n","    if type(x) is float: G = 1\n","    else: G = x.size\n","\n","    ϕ1 = wi*x+θi[0]*np.ones(G)\n","    ϕ2 = θi[1]*np.ones(G)\n","    ϕ3 = θi[2]*np.ones(G)\n","\n","    Ui = np.asarray([[np.cos(ϕ1/2)*np.exp(1j*(ϕ2+ϕ3)/2), -np.sin(ϕ1/2)*np.exp(-1j*(ϕ2-ϕ3)/2)],\n","                    [np.sin(ϕ1/2)*np.exp(1j*(ϕ2-ϕ3)/2),np.cos(ϕ1/2)*np.exp(-1j*(ϕ2+ϕ3)/2)]])    \n","    return np.moveaxis(Ui, -1, 0)  # move last axis to the first position keeping the order of the rest axis"]},{"cell_type":"markdown","metadata":{},"source":["Otra alternativa de modelo estaría basada en las puertas de rotación \n","$$R X(\\theta)=\\exp \\left(-i \\frac{\\theta}{2} X\\right)=\\left(\\begin{array}{cc}\n","\\cos \\frac{\\theta}{2} & -i \\sin \\frac{\\theta}{2} \\\\\n","-i \\sin \\frac{\\theta}{2} & \\cos \\frac{\\theta}{2}\n","\\end{array}\\right)$$\n","$$R Y(\\theta)=\\exp \\left(-i \\frac{\\theta}{2} Y\\right)=\\left(\\begin{array}{cc}\n","\\cos \\frac{\\theta}{2} & -\\sin \\frac{\\theta}{2} \\\\\n","\\sin \\frac{\\theta}{2} & \\cos \\frac{\\theta}{2}\n","\\end{array}\\right)$$\n","$$R Z(\\lambda)=\\exp \\left(-i \\frac{\\lambda}{2} Z\\right)=\\left(\\begin{array}{cc}\n","e^{-i \\frac{\\lambda}{2}} & 0 \\\\\n","0 & e^{i \\frac{\\lambda}{2}}\n","\\end{array}\\right)$$"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"e297dd3a"},"outputs":[],"source":["# file: main_1D.py\n","def layer_rot(x: np.ndarray, θi: np.ndarray, wi: float) -> tuple:\n","    if type(x) is float: G = 1\n","    else: G = x.size\n","\n","    ϕ1 = wi*x+θi[0]*np.ones(G)\n","    ϕ2 = θi[1]\n","    ϕ3 = θi[2]\n","\n","    Rx = np.asarray([[np.cos(ϕ1/2), -1j*np.sin(ϕ1/2)],[-1j*np.sin(ϕ1/2), np.cos(ϕ1/2)]])\n","    Ry = np.array([[np.cos(ϕ2/2), -np.sin(ϕ2/2)],[np.sin(ϕ2/2), np.cos(ϕ2/2)]])\n","    Rz = np.array([[np.cos(ϕ3/2) - 1j*np.sin(ϕ3/2), 0],[0, np.cos(ϕ3/2)+1j*np.sin(ϕ3/2)]])\n","\n","    Ui = np.einsum('mn,np,pqi->mqi', Rz, Ry, Rx)\n","    return np.moveaxis(Ui, -1, 0)  # move last axis to the first position keeping the order of the rest axis"]},{"cell_type":"markdown","metadata":{"id":"5fb9b663"},"source":["We want the first component of $U|0\\rangle=U_L \\cdots U_1|0\\rangle$ to approximate the function $f$:\n","\n","$$f_{\\text{approx}} = \\langle 0 | U_L \\cdots U_1 | 0 \\rangle \\:.$$"]},{"cell_type":"markdown","metadata":{"id":"4c166e78"},"source":["In the particular case the function is a probability distribution, we will return the $|0\\rangle$ qubit's squared amplitude\n","$$f_{\\text{approx}} = |\\langle 0 | U_L \\cdots U_1 | 0 \\rangle|^2 $$"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"3b3106bb"},"outputs":[],"source":["# file: main_1D.py\n","def evalua_modelo(x: np.ndarray, θ: np.ndarray, w: np.ndarray, probability=True, model = 'rotation'):\n","    \"\"\"\n","    Given an array of unitaries, compute the function f(x) that\n","    it represents.\n","    \n","    Parameters\n","    ----------\n","    \n","    x : (L) array\n","        Points in the grid\n","    θ : (M, 3) array\n","        Variational parameters\n","    w : (M) array\n","        variational parameters\n","    probability : True if f(x) >= 0\n","    \n","    Returns\n","    -------\n","    fi : estimate of f(xi) on all elements of 'x'\n","    \n","    \"\"\"\n","    L = w.size\n","    if model == 'rotation':\n","        U = layer_rot(x, θ[:,0], w[0])[:,:,0]\n","        for i in range(1,L):\n","            Ui = layer_rot(x, θ[:,i], w[i])\n","            U = np.einsum('imn,in->im', Ui, U)\n","    else:  \n","        U = layer(x, θ[:,0], w[0])[:,:,0]\n","        for i in range(1,L):\n","            Ui = layer(x, θ[:,i], w[i])\n","            U = np.einsum('imn,in->im', Ui, U)\n","            \n","    return (U[:,0]*np.conjugate(U[:,0])).real if probability else U[:,0]"]},{"cell_type":"markdown","metadata":{"id":"07ff958a"},"source":["Now we create the cost function that approximates our model. Is is a simple mean square error:\n","\n","$$C = \\frac{1}{G}\\sum_{x} |f_{\\text{approx}}(x,w,\\theta) - f(x)|^2$$\n","\n","where $G$ is the size of the grid that approximates the function."]},{"cell_type":"code","execution_count":20,"metadata":{"id":"398c983a"},"outputs":[],"source":["# file: main_1D.py\n","def coste(x, f, θ, w, probability = True, model = 'rotation'):\n","    \"\"\"Cost function of the model.\n","    \n","    Parameters\n","    ----------\n","    x : (G) array\n","        Points in the grid\n","    f : (G) array\n","        Points of the function evaluated in the grid\n","    θ : (M, 3) array\n","        Variational bias parameter.\n","    w : (M) array\n","        Variational weight parameters.\n","    probability : bool\n","        Function is a probability density.\n","        \n","    Returns\n","    -------\n","    (L) array with the mean square error for each x in the grid.\n","        \n","    \"\"\"\n","    f_approx = evalua_modelo(x, θ, w, probability, model = model)\n","    return np.mean(np.abs(f_approx - f)**2)"]},{"cell_type":"markdown","metadata":{"id":"a595426b"},"source":["## Derivative Cost Function"]},{"cell_type":"markdown","metadata":{"id":"a8cac3b7"},"source":["Now that we have our cost function and neural net working, we want to improve it adding an analytic gradient function to the minimizer. In the case the function is not a probability density, it is encoded in the probability amplitud of the $|0\\rangle$ qubit, $f_{\\text{approx}} = \\langle 0 | U | 0 \\rangle$, and the cost function is\n","\n","$$C = \\frac{1}{G}\\sum_{x} |\\langle 0 | U(x,w,\\theta) | 0 \\rangle - f(x)|^2 \\:.$$"]},{"cell_type":"markdown","metadata":{"id":"99aaf37c"},"source":["Taking the derivative respect to the parameter $\\lambda_i$ of the $i$-th layer\n","\n","$$\\frac{\\partial C}{\\partial \\lambda_i} = \\frac{1}{G}\\sum_{x} 2\\, \\text{Re}\\bigg\\{\\big(\\langle 0 | U(x,w,\\theta) | 0 \\rangle - f(x)\\big)\\,\\frac{\\partial \\langle 0 | U(x,w,\\theta) | 0 \\rangle}{\\partial \\lambda_i}\\bigg\\} = $$\n","\n","$$ = \\frac{1}{G}\\sum_{x} 2\\, \\text{Re}\\bigg\\{\\big(\\langle 0 | U(x,w,\\theta) | 0 \\rangle - f(x)\\big)\\,\\langle 0 |U_L \\cdots \\frac{\\partial  U_i(x,w_i,\\theta_i)} {\\partial \\lambda_i} \\cdots U_1 | 0 \\rangle \\bigg\\} \\:. $$"]},{"cell_type":"markdown","metadata":{"id":"9120318a"},"source":["To calculate the derivatives of the rotations easily, we derive the previous formula \n","\n","$$\\frac{\\partial U_i}{\\partial w} = \\frac{1}{2}\\begin{pmatrix} \\cos{(\\phi_1/2+\\pi/2)}\\, e^{i(\\phi_2+\\phi_3)/2} & -\\sin{(\\phi_1/2+\\pi/2)}\\, e^{-i(\\phi_2-\\phi_3)/2} \\\\ \\sin{(\\phi_1/2+\\pi/2)}\\, e^{i(\\phi_2-\\phi_3)/2} & \\cos{(\\phi_1/2+\\pi/2)}\\, e^{-i(\\phi_2+\\phi_3)/2}  \\end{pmatrix}\\frac{\\partial \\phi_1}{\\partial w} = \\frac{1}{2}U_i(\\phi_1+\\pi,\\phi_2,\\phi_3)\\,x$$\n","\n","$$\\frac{\\partial U_i}{\\partial \\theta_0} = \\frac{1}{2}U_i(\\phi_1+\\pi,\\phi_2,\\phi_3)$$\n","\n","$$\\frac{\\partial U_i}{\\partial \\theta_1} = \\frac{1}{2}U_i(\\phi_1,\\phi_2+\\pi,\\phi_3)$$\n","\n","$$\\frac{\\partial U_i}{\\partial \\theta_2} = \\frac{1}{2}U_i(\\phi_1,\\phi_2,\\phi_3+\\pi)$$"]},{"cell_type":"markdown","metadata":{"id":"c9b34244"},"source":["Taking the derivative respect to the parameter $\\lambda_i$ of the $i$-th layer\n","\n","$$\\frac{\\partial C}{\\partial \\lambda_i} = \\frac{1}{G}\\sum_{x} 2\\, \\text{Re}\\bigg\\{\\big(\\langle 0 | U(x,w,\\theta) | 0 \\rangle - f(x)\\big)\\,\\frac{\\partial \\langle 0 | U(x,w,\\theta) | 0 \\rangle}{\\partial \\lambda_i}\\bigg\\} = $$\n","\n","$$ = \\frac{1}{G}\\sum_{x} 2\\, \\text{Re}\\bigg\\{\\big(\\langle 0 | U(x,w,\\theta) | 0 \\rangle - f(x)\\big)\\,\\langle 0 |U_L \\cdots \\frac{\\partial  U_i(x,w_i,\\theta_i)} {\\partial \\lambda_i} \\cdots U_1 | 0 \\rangle \\bigg\\} \\:. $$"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"54ee5ec1"},"outputs":[],"source":["# file: main_1D.py\n","def der_layer(x: np.ndarray, θi: np.ndarray, wi: float, model = 'rotation') -> tuple:\n","    if type(x) is float: G = 1\n","    else: G = x.size\n","    \n","    if model == 'rotation':\n","        ϕ1 = wi*x+θi[0]*np.ones(G)\n","        ϕ2 = θi[1]\n","        ϕ3 = θi[2]\n","\n","        Rx = np.asarray([[np.cos(ϕ1/2), -1j*np.sin(ϕ1/2)],[-1j*np.sin(ϕ1/2), np.cos(ϕ1/2)]])\n","        Ry = np.array([[np.cos(ϕ2/2), -np.sin(ϕ2/2)],[np.sin(ϕ2/2), np.cos(ϕ2/2)]])\n","        Rz = np.array([[np.cos(ϕ3/2) - 1j*np.sin(ϕ3/2), 0],[0, np.cos(ϕ3/2)+1j*np.sin(ϕ3/2)]])\n","\n","        DRx = 1/2*np.asarray([[-np.sin(ϕ1/2), -1j*np.cos(ϕ1/2)],[-1j*np.cos(ϕ1/2), -np.sin(ϕ1/2)]])\n","        DRy = 1/2*np.array([[-np.sin(ϕ2/2), -np.cos(ϕ2/2)],[np.cos(ϕ2/2), -np.sin(ϕ2/2)]])\n","        DRz = 1/2*np.array([[-1j*np.cos(ϕ3/2) - np.sin(ϕ3/2), 0],[0, 1j*np.cos(ϕ3/2)-np.sin(ϕ3/2)]])\n","\n","        Dx = np.einsum('mn,np,pqi->imq', Rz, Ry, DRx)\n","        Dw = np.einsum('mn,np,pqi,i->imq', Rz, Ry, DRx, x)\n","        Dy = np.einsum('mn,np,pqi->imq', Rz, DRy, Rx)\n","        Dz = np.einsum('mn,np,pqi->imq', DRz, Ry, Rx)\n","        \n","    else:\n","        Dx = 1/2*layer(x, np.array([θi[0]+np.pi, θi[1], θi[2]]), wi)\n","        Dw = np.einsum(\"imn,i->imn\", Dx, x)\n","        Dy = 1/2*layer(x, np.array([θi[0], θi[1]+np.pi, θi[2]]), wi)\n","        Dz = 1/2*layer(x, np.array([θi[0], θi[1], θi[2]+np.pi]), wi)\n","\n","    return np.array([Dw, Dx, Dy, Dz])"]},{"cell_type":"markdown","metadata":{"id":"dZSqWJCxA-Og"},"source":["Now we create a function to calculate \n","\n","$$\\langle 0 | \\,U_L \\cdots \\frac{\\partial U_i }{\\partial \\lambda_i}\\cdots U_1\\,| 0 \\rangle$$\n","\n","The program will return an array with layers in the first index, parameter of each layer in the second index and x in the third index. "]},{"cell_type":"markdown","metadata":{"id":"5a691ee7"},"source":["We do it recursively with two loops. First an ascending loop:\n","\n","1. Step 1\n","\n","$$ D[1] = \\frac{\\partial U_1 }{\\partial \\lambda_j}$$\n","\n","$$ A = U_1$$\n","\n","2. Step 2\n","\n","$$ D[2] = \\frac{\\partial U_2 }{\\partial \\lambda_j}A = \\frac{\\partial U_2 }{\\partial \\lambda_j} U_1$$\n","\n","$$ A = U_2 A = U_2 U_1 $$\n","\n","3. Step 3\n","\n","$$ D[3] = \\frac{\\partial U_2 }{\\partial \\lambda_j}A = \\frac{\\partial U_3 }{\\partial \\lambda_j} U_2 U_1$$\n","\n","$$ A = U_3 A = U_3 U_2 U_1$$\n","\n","$$\\vdots$$\n","\n","4. Step i\n","\n","$$ D[i] = \\frac{\\partial U_n }{\\partial \\lambda_j}A $$\n","\n","$$ A = U_i A$$"]},{"cell_type":"markdown","metadata":{"id":"4adc02f2"},"source":["And then a descending loop (L is the last index):\n","\n","1. Step 1\n","\n","$$ D[L-1] = U_L D[L-1] = U_L \\cdots \\frac{\\partial U_i }{\\partial \\lambda_i}\\cdots U_1 $$\n","\n","$$ B = U_L U_{L-1}$$\n","\n","2. Step 2\n","\n","$$ D[L-2] = B D[L-2] = U_L U_{L-1} \\frac{\\partial U_{L-2} }{\\partial \\lambda_j} \\cdots U_1$$\n","\n","$$ B = B \\,U_{L-2} = U_L U_{L-1} U_{L-2} $$\n","\n","$$\\vdots$$\n","\n","4. Step i\n","\n","$$ D[i] = B \\frac{\\partial U_i }{\\partial \\lambda_j} = U_L\\cdots U_{i+1} \\frac{\\partial U_i }{\\partial \\lambda_j}\\cdots U_1 $$\n","\n","$$ B = B U_i = U_L \\cdots U_i$$\n"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"6d1da875"},"outputs":[],"source":["# file: main_1D.py\n","\n","def der_net(x: np.ndarray, θ: np.ndarray, w: np.ndarray, model = 'rotation'):\n","    \"\"\"\"Create recursively the derivatives with respect to each parameter of the entire net. \"\"\"\n","    \n","    L = w.size\n","    G = x.size\n","    A = np.tensordot(np.ones(G), np.identity(2), axes=0)  # dim (G,2,2)\n","    D = np.zeros((L,4,G,2,2), dtype=np.complex128)\n","    \n","    for i in range(L):  \n","        DUi = der_layer(x, θ[:,i], w[i], model = model) # dim (4,G,2,2)\n","        D[i,...] = np.einsum('jimn,inp->jimp', DUi, A)  # j es cada una de las derivadas\n","        # Multiply derivative times next layer\n","        if model == 'rotation':\n","            Ui = layer_rot(x, θ[:,i], w[i])\n","        else:\n","            Ui = layer(x, θ[:,i], w[i])\n","        A = np.einsum('imn,inp->imp', Ui, A)\n","    \n","    # En la primera iteración reaprovechamos el Ui de la capa L\n","    B = Ui\n","    \n","    for i in range(L-2,-1,-1):\n","        D[i,...] = np.einsum('imn,jinp->jimp', B, D[i,...]) \n","        # Multiply derivative times previous layer\n","        if model == 'rotation':\n","            Ui = layer_rot(x, θ[:,i], w[i])\n","        else: \n","            Ui = layer(x, θ[:,i], w[i])\n","        B = np.einsum('imn,inp->imp', B, Ui)\n","     # D is shape (L,4,G,2,2). We also return the model\n","    return D, A \n"]},{"cell_type":"markdown","metadata":{"id":"4b7b8593"},"source":["If we approximate an arbitrary complex function, the cost function is \n","\n","$$ C = \\frac{1}{G} \\sum_{x} |\\,\\langle 0 | U(x,w,\\theta) | 0 \\rangle - f(x) \\,|^{\\,2} \\:,$$"]},{"cell_type":"markdown","metadata":{"id":"450a98a9"},"source":["and its derivative is\n","\n","$$\\frac{\\partial C}{\\partial \\lambda_i} =\\frac{1}{G} \\sum_{x} 2 \\,\\text{Re}\\,\\Big\\{ \\big(\\langle 0 | U(x,w,\\theta) | 0 \\rangle - f(x) \\big)^\\ast \\, \\frac{\\partial \\langle 0 | U | 0 \\rangle}{\\partial \\lambda_i}\\Big\\} = $$\n","\n","$$=\\frac{1}{G} \\sum_{x} 2 \\,\\text{Re}\\,\\Big\\{ \\big(\\langle 0 | U(x,w,\\theta) | 0 \\rangle - f(x) \\big)^\\ast \\,  \\langle 0 | \\,U_L \\cdots \\frac{\\partial U_i }{\\partial \\lambda_i}\\cdots U_1\\,| 0 \\rangle\\Big\\}$$"]},{"cell_type":"markdown","metadata":{"id":"341606ce"},"source":["If we approximate a probability density function instead, the cost function is \n","\n","$$ C = \\frac{1}{G} \\sum_{x} \\Big(|\\langle 0 | U(x,w,\\theta) | 0 \\rangle|^2 - f(x)\\Big)^2 \\:.$$"]},{"cell_type":"markdown","metadata":{"id":"607b682e"},"source":["Then, the derivative of the cost function respect $\\lambda_i$ is\n","\n","$$\\frac{\\partial C}{\\partial \\lambda_i} = \\frac{1}{G} \\sum_{x} 2\\,\\big(|\\langle 0 | U(x,w,\\theta) | 0 \\rangle|^2 - f(x)\\big)\\,2\\,\\text{Re}\\,\\Big\\{\\langle 0 | U | 0 \\rangle^\\ast \\, \\frac{\\partial \\langle 0 | U | 0 \\rangle}{\\partial \\lambda_i}\\Big\\} = $$\n","\n","$$ = \\frac{1}{G} \\sum_{x} 4\\,\\big(|\\langle 0 | U(x,w,\\theta) | 0 \\rangle|^2 - f(x)\\big)\\,\\text{Re}\\,\\Big\\{\\langle 0 | U | 0 \\rangle^\\ast \\, \\langle 0 | \\,U_L \\cdots \\frac{\\partial U_i }{\\partial \\lambda_i}\\cdots U_1\\,| 0 \\rangle\\Big\\} $$"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"db9d33c1"},"outputs":[],"source":["# file: main_1D.py\n","def der_coste(x, f, θ, w, probability = True, return_cost = False, model = 'rotation'):\n","    \"\"\"\"Returns the gradient of the cost function with respect to each parameter. \"\"\"\n","    \n","    L = w.size\n","    G = x.size\n","\n","    if probability:\n","        ders, A = der_net(x, θ, w, model = model)\n","        U = A[:,0,0]\n","        E = U*np.conj(U) - f\n","        # índice i layers, j parametro \n","        der_C = 4/G * np.array([[np.dot(E.real, np.real(np.conj(U)*ders[i,j,:,0,0])) for i in range(L)] for j in range(4)])\n","\n","    else:\n","        ders, A = der_net(x, θ, w, model = model)\n","        U = A[:,0,0]\n","        E = U - f   # error in approximation\n","        der_C = 2/G * np.array([[np.real(np.dot(np.conj(E), ders[i,j,:,0,0])) for i in range(L)] for j in range(4)])\n","        \n","    # devolvemos un array con la misma estructura que ϕ = [w, θ_0, θ_1, θ_2]\n","    if return_cost:\n","        if probability:\n","            return der_C.flatten(), np.mean((np.abs(U*np.conjugate(U)).real - f)**2)\n","        else:\n","            return der_C.flatten(), np.mean(np.abs(U - f)**2)\n","    else: return der_C.flatten() "]},{"cell_type":"markdown","metadata":{},"source":["## Función de coste alternativa"]},{"cell_type":"markdown","metadata":{},"source":["Probamos a usar la función de coste alternativa\n","\n","$$C = \\frac{1}{\\sqrt{G}}\\sqrt{\\sum_{x} |f_{\\text{approx}}(x,w,\\theta) - f(x)|^2}$$\n"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"398c983a"},"outputs":[],"source":["# file: main_1D.py\n","def coste_sqrt(x, f, θ, w, probability, model = 'rotation'):\n","    \"\"\"Cost function of the model.\n","    \n","    Parameters\n","    ----------\n","    x : (G) array\n","        Points in the grid\n","    f : (G) array\n","        Points of the function evaluated in the grid\n","    θ : (M, 3) array\n","        Variational bias parameter.\n","    w : (M) array\n","        Variational weight parameters.\n","    probability : bool\n","        Function is a probability density.\n","        \n","    Returns\n","    -------\n","    (L) array with the mean square error for each x in the grid.\n","        \n","    \"\"\"\n","    return np.sqrt(coste(x, f, θ, w, probability = probability, model = model))"]},{"cell_type":"markdown","metadata":{},"source":["La derivada será\n","\n","$$\\frac{\\partial C}{\\partial \\lambda_i} = \\frac{1}{\\sqrt{G}} \\frac{1}{\\sqrt{\\sum_{x}|f_{\\text{approx}}(x,w,\\theta) - f(x)|^2}} \\sum_{x}\\,\\text{Re}\\,\\Big\\{ \\big(\\langle 0 | U(x,w,\\theta) | 0 \\rangle - f(x) \\big)^\\ast \\,  \\langle 0 | \\,U_L \\cdots \\frac{\\partial U_i }{\\partial \\lambda_i}\\cdots U_1\\,| 0 \\rangle\\Big\\}$$"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"db9d33c1"},"outputs":[],"source":["# file: main_1D.py\n","def der_coste_sqrt(x, f, θ, w, probability = True, return_cost = False, model = 'rotation'):\n","    \"\"\"\"Returns the gradient of the cost function with respect to each parameter. \"\"\"\n","    \n","    L = w.size\n","    G = x.size\n","\n","    if probability:\n","        ders, A = der_net(x, θ, w, model = model)\n","        U = A[:,0,0]\n","        E = (U*np.conj(U)).real - f\n","        # índice i layers, j parametro \n","        der_C = 2/(np.sqrt(G)*np.sqrt(np.sum(np.abs(E)**2)+1e-9)) * np.array([[np.dot(E, np.real(np.conj(U)*ders[i,j,:,0,0])) for i in range(L)] for j in range(4)])\n","\n","    else:\n","        ders, A = der_net(x, θ, w, model = model)\n","        U = A[:,0,0]\n","        E = U - f   # error in approximation\n","        der_C = 1/(np.sqrt(G)*np.sqrt(np.sum(np.abs(E)**2)+1e-9)) * np.array([[np.real(np.dot(np.conj(E), ders[i,j,:,0,0])) for i in range(L)] for j in range(4)])\n","        \n","    # devolvemos un array con la misma estructura que ϕ = [w, θ_0, θ_1, θ_2]\n","    if return_cost:\n","        if probability:\n","            return der_C.flatten(), np.mean((np.abs(U*np.conjugate(U)).real - f)**2)\n","        else:\n","            return der_C.flatten(), np.mean(np.abs(U - f)**2)\n","    else: return der_C.flatten() "]},{"cell_type":"code","execution_count":47,"metadata":{"executionInfo":{"elapsed":412,"status":"ok","timestamp":1648324444696,"user":{"displayName":"Pablo o.O","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4rq9BdYaGSvYJ7xdq7YdC6U4AXSk7jmew-IDIbg=s64","userId":"00473480621421377707"},"user_tz":-60},"id":"qcGiq9GBZmXh"},"outputs":[],"source":["from exportnb import *"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":329},"executionInfo":{"elapsed":250,"status":"error","timestamp":1648324445842,"user":{"displayName":"Pablo o.O","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4rq9BdYaGSvYJ7xdq7YdC6U4AXSk7jmew-IDIbg=s64","userId":"00473480621421377707"},"user_tz":-60},"id":"6ryMpiN5ZmXh","outputId":"d1c7135c-718e-4496-f2c1-590ae1ad964f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Reading notebook main_1D.ipynb\n","Exporting file main_1D.py\n"]}],"source":["export_notebooks(['main_1D.ipynb'], verbose=True)"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["Test = Test_Functions()\n","x, f = Test.plot(31, 'gaussian', interval = (-1,1), show_plot = True)"]},{"cell_type":"code","execution_count":45,"id":"d8578177","metadata":{"executionInfo":{"elapsed":227,"status":"ok","timestamp":1638986806166,"user":{"displayName":"Pablo o.O","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4rq9BdYaGSvYJ7xdq7YdC6U4AXSk7jmew-IDIbg=s64","userId":"00473480621421377707"},"user_tz":-60},"id":"9c_bjuUjMewW"},"outputs":[],"source":["def coste_intermedio(φ):\n","    ω, θ = split(φ)\n","    return coste_sqrt(x, f, θ, ω, True, model = 'rotation')\n","\n","def der_coste_intermedio(φ):\n","    ω, θ = split(φ)\n","    return der_coste_sqrt(x, f, θ, ω, True, model = 'rotation')"]},{"cell_type":"code","execution_count":46,"id":"9735c2a9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1638986806848,"user":{"displayName":"Pablo o.O","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4rq9BdYaGSvYJ7xdq7YdC6U4AXSk7jmew-IDIbg=s64","userId":"00473480621421377707"},"user_tz":-60},"id":"3neoNmWCM9DY","outputId":"87134651-a57a-45d8-9dc4-85342a7734e9"},"outputs":[{"data":{"text/plain":["2.1608822777560752e-08"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["layers = 5\n","φ = np.asarray([-1,-3,4,5,2,8,0,0,1,3,0,1,2,3,6,9,0,1,3,6])\n","check_grad(coste_intermedio, der_coste_intermedio, φ)"]},{"cell_type":"markdown","metadata":{"id":"8ce77361"},"source":["## Training the model"]},{"cell_type":"markdown","metadata":{"id":"6d2502f0"},"source":["Once we have our cost function and its gradient, we can train our machine learning model. We will use the optimization algorithm L-BFGS-B to minimize the cost function. The algorithm will take as input the array \n","\n","$$\\phi = [w, \\theta_0, \\theta_1, \\theta_2]\\:,$$\n","\n","with the parameters of the model."]},{"cell_type":"code","execution_count":26,"metadata":{"id":"IcsyhC8PZmXd"},"outputs":[],"source":["# file: main_1D.py\n","def split(φ):\n","    layers = φ.size // 4\n","    return φ[0:layers], φ[layers:].reshape(3, layers)"]},{"cell_type":"markdown","metadata":{"id":"rB74dkxEZmXe"},"source":["Optimizador con los métodos predispuestos en ``scipy``. "]},{"cell_type":"code","execution_count":18,"metadata":{"id":"EIElXo8PZmXe"},"outputs":[],"source":["# file: main_1D.py\n","def blackbox_minimizer(x, f, φ_init, probability: bool,\n","             opt_method: str = 'L-BFGS-B', print_cost: bool = False, cost_fun = 'sqrt', model = 'rotation'):\n","    \n","    if cost_fun == 'sqrt':\n","        cost_function = globals()[\"coste_sqrt\"]\n","        der_cost_function = globals()[\"der_coste_sqrt\"]\n","    elif cost_fun == 'normal':\n","        cost_function = globals()[\"coste\"]\n","        der_cost_function = globals()[\"der_coste\"]\n","\n","    def coste_intermedio(φ):\n","        w, θ = split(φ)\n","        c = cost_function(x, f, θ, w, probability, model = model)\n","        if print_cost:  print('Valor f. coste: ', c)\n","        return c\n","\n","    def der_coste_intermedio(φ):\n","        w, θ = split(φ)\n","        der_c = der_cost_function(x, f, θ, w, probability, model = model)\n","        if print_cost:  print('Valor der. coste: ', der_c)\n","        return der_c\n","\n","    return minimize(coste_intermedio, φ_init, method = opt_method, jac = der_coste_intermedio, tol = 1e-12, options={'maxiter': 10000})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EIElXo8PZmXe"},"outputs":[],"source":["\n","def spsa_minimizer(x, f, φ_init, probability: bool, print_cost: bool = False, cost_fun = 'sqrt'):\n","    \n","    if cost_fun == 'sqrt':\n","        cost_function = globals()[\"coste_sqrt\"]\n","    elif cost_fun == 'normal':\n","        cost_function = globals()[\"coste\"]\n","\n","    def coste_intermedio(φ):\n","        w, θ = split(φ)\n","        c = cost_function(x, f, θ, w, probability)\n","        if print_cost:  print('Valor f. coste: ', c)\n","        return c\n","\n","    spsa = SPSA(maxiter=20000)\n","    return spsa.optimize(φ_init.size, coste_intermedio, initial_point=φ_init)[0]"]},{"cell_type":"markdown","metadata":{"id":"Df-iS70zZmXe"},"source":["Now we program the ADAM optimizer"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"ieTdBuc9ZmXe"},"outputs":[],"source":["# file: main_1D.py\n","def adam_minimizer(x, f, φ, probability: bool, print_cost: bool = True, plot_cost = False, cost_fun = 'sqrt', model = 'rotation', n_iter = 800,\n","\t\t alpha = 0.01, beta1 = 0.9, beta2 = 0.999, eps=1e-8):\n","\t'''\n","\tParameters\n","\t----------\n","\tn_iter : int\n","        Number of iterations of the optimization algorithm\n","    alpha : float\n","        steps size\n","    beta1 : float\n","        factor for average gradient\n","\tbeta2 : float\n","\t\tfactor for average squared gradient\n","\n","\t'''\n","\tif cost_fun == 'sqrt':\n","\t\tder_cost_function = globals()[\"der_coste_sqrt\"]\n","\telif cost_fun == 'normal':\n","\t\tder_cost_function = globals()[\"der_coste\"]\n","\n","\tnum_params = φ.size\n","\t# initialize first and second moments\n","\tm = np.zeros(num_params)\n","\tv = np.zeros(num_params)\n","\t# Model parameters\n","\tmin_cost = 10\n","\tcost = np.zeros(n_iter)\n","\tfor t in range(n_iter):\n","\t\tw, θ = split(φ)\n","\t\t# g, cost = der_coste(x, f, θ, w, probability, return_cost = True)\n","\t\tg, cost[t] = der_cost_function(x, f, θ, w, probability, return_cost = True, model = model)\n","\t\tif cost[t] < min_cost: \n","\t\t\tmin_cost = cost[t]\n","\t\t\tmin_t = t\n","\t\t\tmin_φ = φ\n","\t\tif print_cost:\n","\t\t\tprint('φ = {φ}  ,  cost = {cost}'.format(φ = φ, cost = cost[t]))\n","\t\tm = beta1 * m + (1.0 - beta1) * g\n","\t\tv = beta2 * v + (1.0 - beta2) * g**2\n","\t\tmhat = m / (1.0 - beta1**(t+1))\n","\t\tvhat = v / (1.0 - beta2**(t+1))\n","\t\tφ = φ - alpha * mhat / (np.sqrt(vhat) + eps)\n","\t# print('El coste mínimo alcanzado es {min_cost} en la iteración {min_t}.'.format(min_cost=min_cost, min_t=min_t))\n","\t# Devolvemos el φ que minimiza la función de coste\n","\tif plot_cost:\n","\t\tplt.plot(range(n_iter), cost)\n","\t\tplt.yscale('log')\n","\t\tplt.show()\n","\treturn min_φ"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"024d748c"},"outputs":[],"source":["# file: main_1D.py\n","def train_perceptron(x: np.ndarray, f: np.ndarray,\n","                     layers: int = 4,\n","                     opt_method: str = 'L-BFGS-B',\n","                     method_params: dict = {'n_iter': 800, 'alpha': 0.01, 'beta1': 0.9, 'beta2': 0.999, 'eps': 1e-8},\n","                     seed: float = 2.0,\n","                     φ_init: Optional[np.ndarray] = None,\n","                     print_cost: bool = False,\n","                     show_plot = True,\n","                     cc = 0.3,\n","                     probability: Optional[np.ndarray] = None,\n","                     plot_cost: bool = False,\n","                     cost_fun: str = 'sqrt',\n","                     plot_title: str = '',\n","                     model = 'rotation' ):\n","\n","    if φ_init is None:\n","        np.random.seed(seed) \n","        φ_init = cc*np.random.randn(layers + 3*layers)\n","\n","    if probability is None:\n","        probability = (f >= 0).all()\n","    \n","    if opt_method == 'ADAM':\n","        φ = adam_minimizer(x,f, φ_init, probability = probability, print_cost = print_cost, plot_cost = plot_cost,\n","                    cost_fun = cost_fun, model = model, **method_params)\n","        result = 0  # resultado a 0 por defecto en este método\n","    elif opt_method == 'SPSA':\n","        φ = spsa_minimizer(x, f, φ_init, probability = probability,\n","        print_cost = print_cost, cost_fun = cost_fun)\n","        result = 0\n","    else:\n","        result = blackbox_minimizer(x, f, φ_init, opt_method = opt_method, probability = probability,\n","        print_cost = print_cost, cost_fun = cost_fun, model = model)\n","        φ = result.x\n","\n","    if show_plot:\n","        ω, θ = split(φ) \n","        f_approx = evalua_modelo(x, θ, ω, probability, model = model)\n","        plt.close('all')\n","        plt.plot(x, f)\n","        plt.plot(x, f_approx.real)\n","        plt.title(plot_title)\n","        plt.show()\n","    \n","    return φ, result"]},{"cell_type":"markdown","metadata":{"id":"33c54abc"},"source":["## Class of functions to approximate"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"e9ad3fa4"},"outputs":[],"source":["# file: main_1D.py\n","class Test_Functions:\n","    '''Usamos mayúslas para denotar clases y minúsculas para atributos.'''\n","    def __init__(self):\n","        style.use(['seaborn-whitegrid'])\n","\n","    def gaussian(x: np.ndarray , mean: float = 0.0, std: float = 0.2, coef = 1):\n","        \"\"\"\n","        Approximate and plot a gaussian function.\n","    \n","        Parameters \n","        ----------\n","        x : np.ndarray\n","            Grid in which to approximate the function.\n","        mean : float \n","            Mean of the gaussian.\n","        std : float\n","            Standard deviation.\n","        coef : float\n","            Factor that multiplies the gaussian.\n","    \n","        Returns\n","        -------\n","        f : Function\n","    \n","        \"\"\"\n","        if coef is None:\n","            coef = (1/(std*np.sqrt(2*pi)))\n","        return coef*np.exp(-(x-mean)**2/(2*std**2))\n","    def lorentzian(x: np.ndarray, x0: float = 0.0, γ: float = 0.2, coef = None):\n","        if coef is None:\n","            coef = γ\n","        return coef*γ/((x-x0)**2+γ**2)\n","    def sine(x: np.ndarray, a: float = 1.0, b: float = 0.0):\n","        return np.sin(a*x+b)\n","    def cos(x: np.ndarray, a: float = 1.0, b: float = 0.0):\n","        return np.cos(a*x+b)\n","    def step(x: np.ndarray, b: float = 0.0, coef: float = 1.0):\n","        return coef*np.heaviside(x, b)\n","    def relu(x: np.ndarray, a: float = 1.0):\n","        if a<=0: raise ValueError('a must be a positive constant')\n","        return np.maximum(0,a*x)\n","    def tanh(x: np.ndarray, a: float = 5.0, coef = 1.0):\n","        return coef*np.tanh(a*x)\n","    def poly(x: np.ndarray):\n","        return -4*x**2*(x**2-1)\n","    def poly2(x: np.ndarray):\n","        return np.abs((1-x**4)*3*x**3)\n","    def cos2_sin2(x: np.ndarray, a: float = 1.0, b: float = 0.0):\n","        return np.cos(a*x+b)**2-np.sin(a*x+b)**2\n","\n","    def plot(self, grid_size: int = 31,\n","            function: str = 'gaussian',\n","            params: dict = {'mean': 0.0, 'std': 0.5, 'coef': None},\n","            interval: tuple = (-1,1),\n","            show_plot = True):\n","\n","        if function == 'gaussian':\n","            x = np.linspace(params['mean']-5*params['std'], params['mean']+5*params['std'], grid_size)\n","        else:\n","            x = np.linspace(interval[0], interval[1], grid_size) \n","        fun = getattr(Test_Functions, function)\n","        f = fun(x, **params)\n","\n","        if show_plot:\n","            plt.close('all')\n","            plt.plot(x,f)\n","            plt.title(function)\n","            plt.show()\n","        return x, f\n","        "]},{"cell_type":"markdown","metadata":{"id":"d3fb2894"},"source":["## Errores"]},{"cell_type":"markdown","metadata":{"id":"bcc97ede"},"source":["Calculamos diferentes errores, como norma L2, L1, norma infinito o la fidelidad:"]},{"cell_type":"markdown","metadata":{"id":"b4215294"},"source":["$$\\text{Error\\_L1} = \\big| \\int f_{\\text{approx}} - f \\big|\\Big/\\int|f|  $$\n","$$\\text{Error\\_L2} = \\sqrt{\\int \\big| f_{\\text{approx}} - f \\big|^2}\\Big/ \\sqrt{\\int f^2}  $$\n","$$\\text{Error\\_max} = \\text{max}\\,(f-f_{\\text{approx}}) $$\n","$$\\text{Fid} = |\\langle\\hat{f}|\\hat{f}_{\\text{approx}}\\rangle|^2 = \\big|\\int f_{\\text{approx}}\\cdot f \\big|^2 \\Big/ \\int f^2 \\cdot \\int f_{\\text{approx}}^2 $$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2e3a4c33"},"outputs":[],"source":["# file: main_1D.py\n","def error_perceptron(φ: np.ndarray,\n","                    function: str = 'gaussian',\n","                    f_params: dict = {'mean': 0.0, 'std': 0.5, 'coef': None},\n","                    interval: tuple = (-1,1),\n","                    method: str = 'quad',\n","                    probability: bool = True,\n","                    model = 'rotation'):\n","    \"\"\"\"\n","    Error in the approximation of the function by the qubit perceptron.\n","    Returns the error measured in different norms.\n","    \n","    \"\"\"\n","    layers = φ.size // 4\n","    w, θ = φ[0:layers], φ[layers:].reshape(3, layers)\n","\n","    # Seleccionamos la función a aproximar\n","    fun = getattr(Test_Functions, function)\n","    # Norma L2\n","    diff_l2 = lambda x: (np.abs(fun(x, **f_params) - evalua_modelo(x, θ, w, probability, model = model)))**2\n","    f2_theo = lambda x: fun(x, **f_params)**2\n","    # Norma L1\n","    diff_abs = lambda x: np.abs(fun(x, **f_params) - evalua_modelo(x, θ, w, probability, model = model))\n","    f_theo_abs = lambda x: np.abs(fun(x, **f_params))\n","    # Fidelity (no hace falta conjugar f porque el modelo es real)\n","    prod_re = lambda x: np.real(fun(x, **f_params)*evalua_modelo(x, θ, w, probability, model = model))\n","    prod_im = lambda x: np.imag(fun(x, **f_params)*evalua_modelo(x, θ, w, probability, model = model))\n","    f2_approx = lambda x: np.abs(evalua_modelo(x, θ, w, probability, model = model))**2\n","    # Norma infinito\n","    y = np.linspace(interval[0], interval[1], 10000)\n","    error_inf = np.max(np.abs(fun(y, **f_params) - evalua_modelo(y, θ, w, probability, model = model)))\n","    # Seleccionamos el método de integración\n","    if method == 'simpson':\n","        # L2 calculation\n","        error_l2 = np.sqrt(integrate.simpson(diff_l2(y), y)) #/np.sqrt(integrate.simpson(f2_theo(y), y))\n","        # L2 calculation\n","        error_l1 = integrate.simpson(diff_abs(y), y) #/integrate.simpson(f_theo_abs(y), y)\n","        # Fidelity calculation\n","        int_prod_squared = integrate.simpson(prod_re(y), y)**2+integrate.simpson(prod_im(y), y)**2\n","        error_infid = 1-int_prod_squared/(integrate.simpson(f2_approx(y), y) * integrate.simpson(f2_theo(y), y))\n","        return error_l2, error_l1, error_inf, error_infid\n","        \n","    elif method == 'quad':\n","        error_l2 = np.sqrt(integrate.quad(diff_l2, interval[0], interval[1], limit=300)[0])\n","        error_l1 = integrate.quad(diff_abs, interval[0], interval[1], limit=300)[0]\n","        int_prod_squared = integrate.quad(prod_re, interval[0], interval[1], limit=300)[0]**2+integrate.quad(prod_im, interval[0], interval[1], limit=300)[0]**2\n","        error_infid = 1 - int_prod_squared/(integrate.quad(f2_approx, interval[0], interval[1], limit=300)[0] * integrate.quad(f2_theo, interval[0], interval[1], limit=300)[0])\n","        return error_l2, error_l1, error_inf, error_infid\n","    else:\n","        raise ValueError('Solo está permitido usar quad o simpson para la integral.')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# file: main_1D.py\n","def plot_errores(layer_list, l2_list, l1_list, inf_list, infid_list, cost_error, function):\n","    plt.close('all')\n","    fig, ax = plt.subplots(1,1)\n","    ax.plot(layer_list, l2_list, linestyle='-', marker='o', markersize = 6, color='#1f77b4', label='L2 norm')\n","    ax.plot(layer_list, l1_list, linestyle='-', marker='^', markersize = 6, color='#ff7f0e', label='L1 norm')\n","    ax.plot(layer_list, inf_list, linestyle='-', marker='D',markersize = 6, color='#2ca02c', label='Infinity norm')\n","    ax.plot(layer_list, infid_list, linestyle='-', marker='*',markersize = 6, color='crimson', label='Infidelity')\n","    ax.plot(layer_list, cost_error, linestyle='-', marker='*',markersize = 6, color='olive', label='Coste')\n","    \n","\n","    ax.set_title('Error vs Number of layers (' + function + ')')\n","    ax.set_xlabel('Layers')\n","    ax.set_ylabel('Error')\n","    ax.legend(loc='upper right', fontsize='large')\n","    plt.yscale('log')\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7e580a63"},"outputs":[],"source":["# file: main_1D.py\n","def graficas_errores(seed, min_layers, max_layers,\n","                    x: Optional[np.ndarray] = None,\n","                    f: Optional[np.ndarray] = None,\n","                    grid_size: int = 31,\n","                    function: str = 'gaussian',\n","                    f_params: dict = {'mean': 0.0, 'std': 2, 'coef': 1},\n","                    interval: tuple = (-1,1),\n","                    int_method: str = 'quad',\n","                    opt_method: str = 'L-BFGS-B',\n","                    φ_init: Optional[np.ndarray] = None,\n","                    probability: Optional[bool] = None,\n","                    show_plot: bool = False,\n","                    show_final_plot: bool = True,\n","                    show_error_plot: bool = True,\n","                    show_diff = False,\n","                    print_cost: bool = False,\n","                    cost_fun: str = 'sqrt',\n","                    incremental_opt: bool = True,\n","                    print_params: bool = False,\n","                    cc: float = 0.3,\n","                    new_layer_position: str = 'random',\n","                    new_layer_coef: float = 0.2,\n","                    plot_cost_error: bool = False,\n","                    model = 'rotation',\n","                    method_params: dict = {'n_iter': 800, 'alpha': 0.01, 'beta1': 0.9, 'beta2': 0.999, 'eps': 1e-8}):\n","    \n","    Test = Test_Functions()\n","    l2_list, l1_list, inf_list, infid_list = [], [], [], []\n","    layer_list = list(range(min_layers, max_layers+1))\n","\n","    if x is None and f is None:\n","        x, f = Test.plot(grid_size, function, f_params, interval = interval, show_plot = show_plot)\n","    if probability is None:\n","        probability = (f >= 0).all()\n","    \n","    np.random.seed(seed)\n","    if φ_init is None:\n","        # cc deberá ser un valor pequeño en principio\n","        φ = cc * np.random.randn(min_layers + 3*min_layers)\n","        if print_params: print('Parámetros iniciales: ', φ)\n","    else: φ = φ_init\n","\n","    mean_diff = np.zeros(max_layers-min_layers)\n","    std_diff = np.zeros(max_layers-min_layers)\n","    cost_error = np.zeros(max_layers-min_layers+1)\n","\n","    for i, layer in enumerate(layer_list):\n","        φ, result = train_perceptron(x, f, layers = layer, probability = probability, opt_method = opt_method , seed = seed,\n","                                 φ_init = φ, show_plot = show_plot, method_params = method_params, print_cost = print_cost,\n","                                 plot_title = function + ' optimized with ' + opt_method, cost_fun = cost_fun, model = model)\n","        # print('Los parámetros óptimos en la capa {layer} son {φ}.\\n'.format(layer = layer, φ=φ))\n","        error_l2, error_l1, error_inf, error_infid = error_perceptron(φ, function, f_params, interval, int_method, probability, model = model)\n","        \n","        ω, θ = split(φ)\n","        cost_error[i] = coste(x,f,θ,ω,probability, model = model)\n","        # Guardamos la diferencia entre el φ optimizado de la anterior capa y de esta\n","        if layer > min_layers:\n","            if new_layer_position == 'final':\n","                diff_φ = φ.reshape(4,layer).T.flatten()[0:4*(layer-1)] - φ_old.reshape(4,layer-1).T.flatten()\n","                mean_diff[i-1] = np.mean(np.abs(diff_φ))\n","                std_diff[i-1] = np.std(np.abs(diff_φ))\n","            elif new_layer_position == 'initial':\n","                diff_φ = φ.reshape(4,layer).T.flatten()[4:4*layer] - φ_old.reshape(4,layer-1).T.flatten()\n","                mean_diff[i-1] = np.mean(np.abs(diff_φ))\n","                std_diff[i-1] = np.std(np.abs(diff_φ))\n","        φ_old = φ\n","\n","        l2_list.append(error_l2)\n","        l1_list.append(error_l1)\n","        inf_list.append(error_inf)\n","        infid_list.append(error_infid)\n","\n","        if layer == max_layers:\n","            if show_final_plot:\n","                ω, θ = φ[0:layer], φ[layer:].reshape(3, layer) \n","                f_approx = evalua_modelo(x, θ, ω, probability, model = model)\n","                plt.close('all')\n","                plt.plot(x, f)\n","                plt.plot(x, f_approx.real)\n","                plt.title(function + ' optimization with ' + opt_method)\n","                plt.show()\n","            break\n","        if incremental_opt is True:\n","            # Inicializamos una nueva capa en la posición indicada\n","            if new_layer_position == 'random':\n","                i = np.random.randint(0, high=layer+1, dtype=int)\n","            elif new_layer_position == 'final':\n","                i = layer\n","            elif new_layer_position == 'initial':\n","                i = 0\n","            elif new_layer_position == 'middle':\n","                i = min_layers + (layer-min_layers)//2 \n","            else: raise ValueError('El valor de new_layer_position = {a} no es válido.'.format(a = new_layer_position))\n","            # Añadimos la nueva capa con valores cercanos a 0\n","            new_layer_val = new_layer_coef * np.random.randn(4)\n","            #new_layer_val = 0.3/(i+1) * np.random.randn(4)\n","            φ = np.insert(φ, i, new_layer_val[0])  # phi [w1, ...wn, theta1, theta2, theta3]\n","            φ = np.insert(φ, i+1+layer, new_layer_val[1])\n","            φ = np.insert(φ, i+2+2*layer, new_layer_val[2])\n","            φ = np.insert(φ, i+3+3*layer, new_layer_val[3])\n","        else:\n","            φ = cc * np.random.randn(layer+1 + 3*layer+3)\n","        # print('Los parámetros con capa añadida son {φ}.\\n'.format(φ=φ))\n","\n","    if print_params: print('Parámetros finales: ', φ)\n","    # Hacemos una integración numérica para calcular el error de la aproximación\n","    if show_error_plot:\n","        plot_errores(layer_list, l2_list, l1_list, inf_list, infid_list, cost_error, function)\n","\n","    if plot_cost_error:\n","        plt.close()\n","        plt.figure(figsize=(6, 5), dpi=80)\n","        plt.plot(layer_list, cost_error, ls = '--', marker = '^', ms = 14)\n","        plt.yscale('log')\n","        plt.show()\n","\n","    return l2_list, l1_list, inf_list, infid_list, cost_error, mean_diff, std_diff, seed"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["# file: main_1D.py\n","\n","def mean_seed_errores(min_layers, max_layers,\n","                    x: Optional[np.ndarray] = None,\n","                    f: Optional[np.ndarray] = None,\n","                    grid_size: int = 31,\n","                    function: str = 'gaussian',\n","                    f_params: dict = {'mean': 0.0, 'std': 2, 'coef': 1},\n","                    interval: tuple = (-1,1),\n","                    int_method: str = 'quad',\n","                    opt_method: str = 'L-BFGS-B',\n","                    φ_init: Optional[np.ndarray] = None,\n","                    probability: Optional[bool] = None,\n","                    show_plot: bool = False,\n","                    show_final_plot: bool = True,\n","                    show_error_plot: bool = True,\n","                    show_diff = False,\n","                    print_cost: bool = False,\n","                    cost_fun: str = 'sqrt',\n","                    incremental_opt: bool = True,\n","                    print_params: bool = False,\n","                    cc: float = 0.3,\n","                    new_layer_position: str = 'random',\n","                    new_layer_coef: float = 0.2,\n","                    plot_cost_error: bool = False,\n","                    num_seed = 15,\n","                    filename = 'prueba',\n","                    model = 'rotation',\n","                    method_params: dict = {'n_iter': 800, 'alpha': 0.01, 'beta1': 0.9, 'beta2': 0.999, 'eps': 1e-8}):          \n","\n","    num_layer = max_layers - min_layers + 1\n","    l2, l1, inf, fid, cost = np.zeros(num_layer), np.zeros(num_layer), np.zeros(num_layer), np.zeros(num_layer), np.zeros(num_layer)\n","\n","    layer_list = list(range(min_layers, max_layers+1))\n","    cost_array = np.zeros((num_seed,num_layer))\n","    l1_array = np.zeros((num_seed,num_layer))\n","    l2_array = np.zeros((num_seed,num_layer))\n","    fid_array = np.zeros((num_seed,num_layer))\n","    inf_array = np.zeros((num_seed,num_layer))\n","    mean_diff_array = np.zeros((num_seed,num_layer-1))\n","    std_diff_array = np.zeros((num_seed,num_layer-1))\n","    seed_array = np.random.choice(range(0,2000), num_seed, replace=False)\n","  \n","    for i, seed in enumerate(seed_array):\n","        # layer_list, l2_list, l1_list, inf_list, fid_list, cost_list, mean_diff, std_diff = graficas_intermedio(seed)\n","        l2_list, l1_list, inf_list, fid_list, cost_list, mean_diff, std_diff, seed = graficas_errores(seed, min_layers = min_layers, max_layers = max_layers, x = x, f = f, grid_size = grid_size, function = function, \n","            f_params = f_params,interval = interval,int_method = int_method,opt_method = opt_method,φ_init = φ_init,\n","            show_plot = show_plot, show_final_plot = show_final_plot,show_error_plot = show_error_plot, show_diff = show_diff,\n","            print_cost = print_cost,cost_fun = cost_fun,incremental_opt = incremental_opt,print_params = print_params, cc = cc,\n","            new_layer_position = new_layer_position,new_layer_coef = new_layer_coef,plot_cost_error = plot_cost_error,\n","            method_params=method_params, probability = probability, model = model)\n","        # Seeds en el eje 0 y capas en el eje 1. Queremos las seeds en cada box plot.'''\n","        cost_array[i,:]= np.array(cost_list)\n","        l1_array[i,:]= np.array(l1_list)\n","        l2_array[i,:]= np.array(l2_list)\n","        fid_array[i,:]= np.array(fid_list)\n","        inf_array[i,:]= np.array(inf_list)\n","        mean_diff_array[i, :] = mean_diff\n","        std_diff_array[i, :] = std_diff\n","\n","    with open(filename+'.pkl', 'wb') as file:\n","        pickle.dump((layer_list, l2_array, l1_array, inf_array, fid_array, cost_array, seed_array), file)\n","    \n","    with open(filename+'_param_diff.pkl', 'wb') as file:\n","        pickle.dump((mean_diff_array, std_diff_array), file)\n","\n","    l2 = l2/num_seed\n","    l1 = l1/num_seed\n","    inf = inf/num_seed\n","    fid = fid/num_seed\n","    cost = cost/num_seed\n","\n","    plot_errores(layer_list, l2, l1, inf, fid, cost, function)\n","    return layer_list, l2, l1, inf, fid, cost, seed_array\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def mean_seed_errores_parallel(min_layers, max_layers,\n","                    x: Optional[np.ndarray] = None,\n","                    f: Optional[np.ndarray] = None,\n","                    grid_size: int = 31,\n","                    function: str = 'gaussian',\n","                    f_params: dict = {'mean': 0.0, 'std': 2, 'coef': 1},\n","                    interval: tuple = (-1,1),\n","                    int_method: str = 'quad',\n","                    opt_method: str = 'L-BFGS-B',\n","                    φ_init: Optional[np.ndarray] = None,\n","                    probability: Optional[bool] = None,\n","                    show_plot: bool = False,\n","                    show_final_plot: bool = True,\n","                    show_error_plot: bool = True,\n","                    show_diff = False,\n","                    print_cost: bool = False,\n","                    cost_fun: str = 'sqrt',\n","                    incremental_opt: bool = True,\n","                    print_params: bool = True,\n","                    cc: float = 0.3,\n","                    new_layer_position: str = 'random',\n","                    new_layer_coef: float = 0.2,\n","                    plot_cost_error: bool = False,\n","                    num_seed = 15,\n","                    filename = 'prueba',\n","                    save_seeds: bool = False,\n","                    save_param_diff: bool = False,\n","                    model = 'rotation',\n","                    method_params: dict = {'n_iter': 800, 'alpha': 0.01, 'beta1': 0.9, 'beta2': 0.999, 'eps': 1e-8}):          \n","\n","    num_layer = max_layers - min_layers + 1\n","\n","    layer_list = list(range(min_layers, max_layers+1))\n","    cost_array = np.zeros((num_seed,num_layer))\n","    l1_array = np.zeros((num_seed,num_layer))\n","    l2_array = np.zeros((num_seed,num_layer))\n","    fid_array = np.zeros((num_seed,num_layer))\n","    inf_array = np.zeros((num_seed,num_layer))\n","    mean_diff_array = np.zeros((num_seed,num_layer-1))\n","    std_diff_array = np.zeros((num_seed,num_layer-1))\n","\n","    print('Comienzan los cálculos.')\n","\n","    # Computación paralela\n","    MPI.pickle.__init__(dill.dumps, dill.loads)\n","    comm = MPI.COMM_WORLD\n","    size = comm.Get_size()\n","    rank = comm.Get_rank()\n","    num_seed_node = num_seed // size\n","\n","    seed_array = np.random.choice(range(rank*2000,(rank+1)*2000), num_seed_node, replace=False)\n","\n","    # Computación multiprocesador\n","    with ProcessingPool(cpu_count()) as p:\n","        # l2_list, l1_list, inf_list, fid_list, cost_list, mean_diff, std_diff\n","        results = p.map(lambda seed: graficas_errores(seed, min_layers = min_layers, max_layers = max_layers,\n","            x = x, f = f, grid_size = grid_size, function = function, \n","            f_params = f_params,interval = interval,int_method = int_method,opt_method = opt_method,φ_init = φ_init,\n","            show_plot = show_plot, show_final_plot = show_final_plot,show_error_plot = show_error_plot,show_diff = show_diff,\n","            print_cost = print_cost,cost_fun = cost_fun,incremental_opt = incremental_opt,print_params = print_params, cc = cc,\n","            new_layer_position = new_layer_position,new_layer_coef = new_layer_coef,plot_cost_error = plot_cost_error,\n","            method_params=method_params, probability = probability, model = model), seed_array)\n","\n","    print('Cálculos terminados.')\n","\n","    l2_array = np.array([res[0] for res in results]) # array de dim (seeds_node)x(layers)\n","    l1_array = np.array([res[1] for res in results])\n","    inf_array = np.array([res[2] for res in results])\n","    fid_array = np.array([res[3] for res in results])\n","    cost_array = np.array([res[4] for res in results])\n","    mean_diff_array = np.array([res[5] for res in results])\n","    std_diff_array = np.array([res[6] for res in results])\n","\n","    # dim sendbuf (results_node)x(seeds_node)x(layers)\n","    errors_send = np.array([l2_array, l1_array, inf_array, fid_array, cost_array]) \n","    diff_send = np.array([mean_diff_array, std_diff_array]) \n","    seeds_send = np.array([res[7] for res in results])\n","\n","    errors_receive = None\n","    diff_receive = None\n","    seeds_receive = None\n","\n","    if rank == 0:\n","        # aquí recibiremos los datos del resto de nodos\n","        errors_receive = np.zeros([size, 5, num_seed_node, num_layer]) \n","        diff_receive = np.zeros([size, 2, num_seed_node, num_layer-1])\n","        seeds_receive = np.zeros([size, num_seed_node])\n","\n","\n","    # comm.Barrier()   # wait for everybody to synchronize _here_\n","    comm.Gather(seeds_send, seeds_receive, root=0) # El nodo 0 recibe el resto de arrays en una lista [array1, array2, ...]\n","    # comm.Barrier()   # wait for everybody to synchronize _here_\n","    comm.Gather(errors_send, errors_receive, root=0) # El nodo 0 recibe el resto de arrays en una lista [array1, array2, ...]\n","    # comm.Barrier()  \n","    comm.Gather(diff_send, diff_receive, root=0) # El nodo 0 recibe el resto de arrays en una lista [array1, array2, ...]\n","    # comm.Barrier()  \n","\n","    if rank == 0:\n","        # dim results (nodes)x(results_node)x(seeds_node)x(layers)\n","        errors_receive = np.swapaxes(errors_receive,1,2)\n","        diff_receive = np.swapaxes(diff_receive,1,2)\n","        # dim results (seeds)x(results_node)x(layers)\n","        errors_results = np.concatenate(errors_receive, axis=0)\n","        diff_results = np.concatenate(diff_receive, axis=0)\n","        # dim results (results_node)x(seeds)x(layers)\n","        errors_results = np.swapaxes(errors_results, 0,1)\n","        diff_results = np.swapaxes(diff_results, 0,1)\n","\n","        with open(filename+'.pkl', 'wb') as file:\n","            pickle.dump((layer_list, errors_results[0,], errors_results[1,], errors_results[2,], errors_results[3,], errors_results[4,]), file)\n","        \n","        if save_param_diff:\n","            with open(filename+'_param_diff.pkl', 'wb') as file:\n","                pickle.dump((diff_results[0,], diff_results[1,]), file)\n","\n","        seeds_results = np.concatenate(seeds_receive, axis=0)\n","        if save_seeds:\n","            with open(filename+'_seeds.pkl', 'wb') as file:\n","                pickle.dump(seeds_results, file)\n","\n","        '''l2 = l2/num_seed\n","        l1 = l1/num_seed\n","        inf = inf/num_seed\n","        fid = fid/num_seed\n","        cost = cost/num_seed\n","\n","        plot_errores(layer_list, l2, l1, inf, fid, cost, function)\n","        return layer_list, l2, l1, inf, fid, cost, seed_array'''\n","    "]},{"cell_type":"markdown","metadata":{"id":"FQF1DxxTZmXh"},"source":["## Export notebook"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":412,"status":"ok","timestamp":1648324444696,"user":{"displayName":"Pablo o.O","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4rq9BdYaGSvYJ7xdq7YdC6U4AXSk7jmew-IDIbg=s64","userId":"00473480621421377707"},"user_tz":-60},"id":"qcGiq9GBZmXh"},"outputs":[],"source":["from exportnb import *"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":329},"executionInfo":{"elapsed":250,"status":"error","timestamp":1648324445842,"user":{"displayName":"Pablo o.O","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4rq9BdYaGSvYJ7xdq7YdC6U4AXSk7jmew-IDIbg=s64","userId":"00473480621421377707"},"user_tz":-60},"id":"6ryMpiN5ZmXh","outputId":"d1c7135c-718e-4496-f2c1-590ae1ad964f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Reading notebook main_1D.ipynb\n","Exporting file main_1D.py\n"]}],"source":["export_notebooks(['main_1D.ipynb'], verbose=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"main_1D.ipynb","provenance":[]},"interpreter":{"hash":"a7013974fffeed3b051300295b1503215c2ff339c4a5745dabd6db85632ac1be"},"kernelspec":{"display_name":"Python 3.10.4 ('QC_env')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
